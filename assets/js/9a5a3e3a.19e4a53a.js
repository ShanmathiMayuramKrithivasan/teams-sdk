"use strict";(self.webpackChunkteams_md=self.webpackChunkteams_md||[]).push([[803],{16766:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>c,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"typescript/in-depth-guides/ai/keeping-state","title":"Keeping State","description":"\x3c!--","source":"@site/docs/main/typescript/in-depth-guides/ai/keeping-state.mdx","sourceDirName":"typescript/in-depth-guides/ai","slug":"/typescript/in-depth-guides/ai/keeping-state","permalink":"/teams-sdk/typescript/in-depth-guides/ai/keeping-state","draft":false,"unlisted":false,"editUrl":"https://github.com/microsoft/teams-sdk/tree/main/teams.md/docs/main/typescript/in-depth-guides/ai/keeping-state.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"sidebar_label":"Keeping State","title":"Keeping State","summary":"Guide to managing conversation state in LLM interactions, explaining how to maintain chat history using ChatPrompt\'s state management capabilities and implementing custom persistence strategies for multi-conversation scenarios."},"sidebar":"default","previous":{"title":"Function Calling","permalink":"/teams-sdk/typescript/in-depth-guides/ai/function-calling"},"next":{"title":"Best Practices","permalink":"/teams-sdk/typescript/in-depth-guides/ai/best-practices"}}');var s=n(62540),a=n(43023),o=n(26802);const r={sidebar_position:4,sidebar_label:"Keeping State",title:"Keeping State",summary:"Guide to managing conversation state in LLM interactions, explaining how to maintain chat history using ChatPrompt's state management capabilities and implementing custom persistence strategies for multi-conversation scenarios."},c="Keeping State",p={},l=[{value:"State Initialization",id:"state-initialization",level:2},{value:"Usage Example",id:"usage-example",level:2}];function d(e){const t={admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"keeping-state",children:"Keeping State"})}),"\n",(0,s.jsx)(t.p,{children:"By default, LLMs are not stateful. This means that they do not remember previous messages or context when generating a response.\nIt's common practice to keep state of the conversation history in your application and pass it to the LLM each time you make a request."}),"\n",(0,s.jsxs)(t.p,{children:["By default, the ",(0,s.jsx)(t.code,{children:"ChatPrompt"})," instance will create a temporary in-memory store to keep track of the conversation history. This is beneficial\nwhen you want to use it to generate an LLM response, but not persist the conversation history. But in other cases, you may want to keep the conversation history"]}),"\n",(0,s.jsx)(t.admonition,{type:"warning",children:(0,s.jsxs)(t.p,{children:["By reusing the same ",(0,s.jsx)(t.code,{children:"ChatPrompt"})," class instance across multiple conversations will lead to the conversation history being shared across all conversations. Which is usually not the desired behavior."]})}),"\n",(0,s.jsxs)(t.p,{children:["To avoid this, you need to get messages from your persistent (or in-memory) store and pass it in to the ",(0,s.jsx)(t.code,{children:"ChatPrompt"}),"."]}),"\n",(0,s.jsx)(t.admonition,{type:"note",children:(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"ChatPrompt"})," class will modify the messages object that's passed into it. So if you want to manually manage it, you need to make a copy of the messages object before passing it in."]})}),"\n",(0,s.jsx)(t.h2,{id:"state-initialization",children:"State Initialization"}),"\n",(0,s.jsx)(t.p,{children:"Here's how to initialize and manage conversation state for multiple conversations:"}),"\n",(0,s.jsx)(o.A,{language:"typescript",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:"import { ChatPrompt, IChatModel, Message } from '@microsoft/teams.ai';\nimport { ActivityLike, IMessageActivity, MessageActivity } from '@microsoft/teams.api';\n// ...\n\n// Simple in-memory store for conversation histories\n// In your application, it may be a good idea to use a more\n// persistent store backed by a database or other storage solution\nconst conversationStore = new Map<string, Message[]>();\n\nconst getOrCreateConversationHistory = (conversationId: string) => {\n  // Check if conversation history exists\n  const existingMessages = conversationStore.get(conversationId);\n  if (existingMessages) {\n    return existingMessages;\n  }\n  // If not, create a new conversation history\n  const newMessages: Message[] = [];\n  conversationStore.set(conversationId, newMessages);\n  return newMessages;\n};\n"})})}),"\n",(0,s.jsx)(t.h2,{id:"usage-example",children:"Usage Example"}),"\n",(0,s.jsx)(o.A,{language:"typescript",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:"/**\n * Example of a stateful conversation handler that maintains conversation history\n * using an in-memory store keyed by conversation ID.\n * @param model The chat model to use\n * @param activity The incoming activity\n * @param send Function to send an activity\n */\nexport const handleStatefulConversation = async (\n  model: IChatModel,\n  activity: IMessageActivity,\n  send: (activity: ActivityLike) => Promise<any>,\n  log: ILogger\n) => {\n  log.info('Received message', activity.text);\n\n  // Retrieve existing conversation history or initialize new one\n  const existingMessages = getOrCreateConversationHistory(activity.conversation.id);\n\n  log.info('Existing messages before sending to prompt', existingMessages);\n\n  // Create prompt with existing messages\n  const prompt = new ChatPrompt({\n    instructions: 'You are a helpful assistant.',\n    model,\n    messages: existingMessages, // Pass in existing conversation history\n  });\n\n  const result = await prompt.send(activity.text);\n\n  if (result) {\n    await send(\n      result.content != null\n        ? new MessageActivity(result.content).addAiGenerated()\n        : 'I did not generate a response.'\n    );\n  }\n\n  log.info('Messages after sending to prompt:', existingMessages);\n};\n"})})}),"\n",(0,s.jsx)(o.A,{language:"typescript",children:(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Stateful Chat Example",src:n(21341).A+"",width:"1588",height:"1162"})})})]})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},21341:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/stateful-chat-example-503f5e716853958efa6f8c4537b5e193.png"},26802:(e,t,n)=>{n.d(t,{A:()=>a});var i=n(22147),s=n(62540);function a({language:e,children:t}){return(0,i.zy)().pathname.includes(`/${e}/`)?(0,s.jsx)(s.Fragment,{children:t}):null}},43023:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var i=n(63696);const s={},a=i.createContext(s);function o(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);